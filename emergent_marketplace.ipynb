{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHtpN8ddUktAGUL+bJfhaa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "streamlit==1.31.0\n",
        "pandas>=2.0.0\n",
        "numpy>=1.24.0\n",
        "plotly>=5.18.0\n",
        "scikit-learn>=1.3.0\n",
        "yfinance>=0.2.36\n",
        "# tensorflow-quantum  <-- (Uncomment this only if you are ready for a huge build size)"
      ],
      "metadata": {
        "id": "3Ma8VrmVxU4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit==1.31.0 pandas>=2.0.0 numpy>=1.24.0 plotly>=5.18.0 scikit-learn>=1.3.0 yfinance>=0.2.36 pandas_datareader polygon-api-client\n",
        "import streamlit as st\n",
        "import time\n",
        "\n",
        "# Page Configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"My Project Interface\",\n",
        "    page_icon=\"âš¡\",\n",
        "    layout=\"centered\"\n",
        ")\n",
        "\n",
        "# Header\n",
        "st.title(\"Project Dashboard\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Sidebar for inputs\n",
        "with st.sidebar:\n",
        "    st.header(\"Configuration\")\n",
        "    input_mode = st.selectbox(\"Select Mode\", [\"Standard\", \"Advanced\", \"Debug\"])\n",
        "    user_param = st.slider(\"Parameter Tuning\", 0, 100, 50)\n",
        "\n",
        "    st.info(\"Adjust settings above before running the process.\")\n",
        "\n",
        "# Main Interface\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.subheader(\"Input Data\")\n",
        "    text_input = st.text_area(\"Enter your data or query here:\", height=150)\n",
        "\n",
        "with col2:\n",
        "    st.subheader(\"System Status\")\n",
        "    status_placeholder = st.empty()\n",
        "    status_placeholder.success(\"System Ready\")\n",
        "\n",
        "# Action Button\n",
        "if st.button(\"Run Process\", type=\"primary\", use_container_width=True):\n",
        "    if not text_input:\n",
        "        st.warning(\"Please provide input data first.\")\n",
        "    else:\n",
        "        # ---------------------------------------------------------\n",
        "        # YOUR LOGIC GOES HERE\n",
        "        # Example: result = my_function(text_input, user_param)\n",
        "        # ---------------------------------------------------------\n",
        "\n",
        "        status_placeholder.info(\"Processing...\")\n",
        "        progress_bar = st.progress(0)\n",
        "\n",
        "        # Simulating work\n",
        "        for i in range(100):\n",
        "            time.sleep(0.01)\n",
        "            progress_bar.progress(i + 1)\n",
        "\n",
        "        status_placeholder.success(\"Complete!\")\n",
        "\n",
        "        # Display Results\n",
        "        st.markdown(\"### Results\")\n",
        "        st.success(f\"Processed: {text_input[:20]}... with Parameter: {user_param}\")\n",
        "        st.json({\"status\": \"success\", \"mode\": input_mode, \"output_value\": 42})\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.caption(\"Deployed via GitHub & Railway\")"
      ],
      "metadata": {
        "id": "B22wyaZYw5TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QZGq1IulN_-"
      },
      "outputs": [],
      "source": [
        "import os, time, random, threading, shelve\n",
        "from datetime import datetime, timedelta\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import yfinance as yf\n",
        "from polygon import RESTClient\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Quick env setup examples (run in a separate cell or uncomment here)\n",
        "#%env ALPHAVANTAGE_KEY=your_alpha_key_here\n",
        "#%env SEC_USER_AGENT=youremail@example.com\n",
        "\n",
        "ALPHAVANTAGE_KEY = os.getenv(\"ALPHAVANTAGE_KEY\", \"\")\n",
        "SEC_USER_AGENT = os.getenv(\"SEC_USER_AGENT\", \"your_email@example.com\")\n",
        "\n",
        "# Config\n",
        "CACHE_FILE = \"market_fetch_cache.db\"   # shelve file (disk cache)\n",
        "CACHE_TTL = 300                        # seconds\n",
        "PROVIDER_MIN_INTERVALS = {\n",
        "    \"yfinance\": 0.2,\n",
        "    \"stooq\": 0.5,\n",
        "    \"alpha\": 12.0,\n",
        "    \"yahoo_json\": 0.5,\n",
        "    \"sec\": 0.5,\n",
        "    \"polygon\": 0.5\n",
        "}\n",
        "MAX_WORKERS = 6\n",
        "\n",
        "# Simulation defaults\n",
        "derivative_per_ticker = 3\n",
        "eta = 0.4\n",
        "phi_ladder_vals = [0.3, 0.8, 1.618]\n",
        "update_interval = 0.1\n",
        "max_steps = 200\n",
        "cross_sample_k = 10\n",
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Advanced Market Structure Parameters\n",
        "ENABLE_BASEL_CONSTRAINTS = True\n",
        "MAX_RISK_RATIO = 0.3  # max % of capital per agent in risky assets\n",
        "DELEVERAGING_SEVERITY = 0.02  # how aggressively overexposed agents deleverage\n",
        "\n",
        "ENABLE_TIERED_LIQUIDITY = True\n",
        "SLOW_AGENT_RATIO = 0.3  # fraction of agents that are \"slow\" (institutional)\n",
        "SLOW_REACTION_RATE = 0.05  # how slowly slow agents respond\n",
        "SLOW_AGENT_Z3_WEIGHT = 2.0  # institutional influence on consensus\n",
        "\n",
        "ENABLE_DELIVERY_FRICTION = True\n",
        "COMMODITY_TICKERS = ['GLD', 'SLV', 'GC=F', 'SI=F']  # add your metal tickers\n",
        "MAX_DELIVERY_RATE = 0.02  # max % of volume that can be physically delivered per step\n",
        "SCARCITY_PREMIUM_FACTOR = 0.1  # price boost when physical is scarce\n",
        "\n",
        "ENABLE_REGIME_SHOCKS = True\n",
        "SHOCK_THRESHOLD = 0.10  # trigger shock when cluster diverges >10% from baseline\n",
        "SHOCK_MAGNITUDE = 0.15  # size of geopolitical shock\n",
        "LATAM_ENERGY_TICKERS = ['PBR', 'EC', 'VALE']  # example cluster\n",
        "\n",
        "ENABLE_MEMORY = True\n",
        "MEMORY_ALPHA = 0.1  # weight of new info vs history (lower = more memory)\n",
        "MEMORY_INFLUENCE = 0.05  # how much memory pulls prices\n",
        "\n",
        "ENABLE_INFLUENCE_WEIGHTING = True\n",
        "INFLUENCE_POWER_SCALE = 10.0  # amplification factor for big money\n",
        "\n",
        "# Disk cache (shelve) with TTL\n",
        "_cache_lock = threading.Lock()\n",
        "\n",
        "def cache_get(key):\n",
        "    with _cache_lock:\n",
        "        with shelve.open(CACHE_FILE) as db:\n",
        "            if key in db:\n",
        "                ts, val = db[key]\n",
        "                if time.time() - ts < CACHE_TTL:\n",
        "                    return val\n",
        "                else:\n",
        "                    del db[key]\n",
        "            return None\n",
        "\n",
        "def cache_set(key, val):\n",
        "    with _cache_lock:\n",
        "        with shelve.open(CACHE_FILE) as db:\n",
        "            db[key] = (time.time(), val)\n",
        "\n",
        "# Per-provider rate limiter\n",
        "_provider_locks = {name: threading.Lock() for name in PROVIDER_MIN_INTERVALS}\n",
        "_provider_last_call = {name: 0.0 for name in PROVIDER_MIN_INTERVALS}\n",
        "\n",
        "def rate_limit(provider_name):\n",
        "    min_interval = PROVIDER_MIN_INTERVALS.get(provider_name, 0.5)\n",
        "    lock = _provider_locks[provider_name]\n",
        "    with lock:\n",
        "        now = time.time()\n",
        "        elapsed = now - _provider_last_call[provider_name]\n",
        "        wait = max(0.0, min_interval - elapsed)\n",
        "        if wait > 0:\n",
        "            time.sleep(wait)\n",
        "        _provider_last_call[provider_name] = time.time()\n",
        "\n",
        "# Backoff retry helper\n",
        "def backoff_retry(fn, max_attempts=4, base_delay=0.5):\n",
        "    last_exc = None\n",
        "    for attempt in range(1, max_attempts + 1):\n",
        "        try:\n",
        "            return fn()\n",
        "        except Exception as e:\n",
        "            last_exc = e\n",
        "            if attempt == max_attempts:\n",
        "                raise\n",
        "            sleep = base_delay * (2 ** (attempt - 1)) * (0.8 + 0.4 * random.random())\n",
        "            time.sleep(sleep)\n",
        "    raise last_exc\n",
        "\n",
        "# Providers (price-focused)\n",
        "def provider_yfinance_quote(ticker):\n",
        "    key = f\"yf_quote:{ticker}\"\n",
        "    cached = cache_get(key)\n",
        "    if cached is not None:\n",
        "        return cached\n",
        "    def _call():\n",
        "        rate_limit(\"yfinance\")\n",
        "        t = yf.Ticker(ticker)\n",
        "        hist = t.history(period=\"1d\", interval=\"1d\")\n",
        "        if hist is None or hist.empty:\n",
        "            raise RuntimeError(\"yfinance empty\")\n",
        "        latest = hist.iloc[-1]\n",
        "        out = {\"provider\": \"yfinance\", \"ticker\": ticker, \"price\": float(latest[\"Close\"]), \"volume\": int(latest.get(\"Volume\", 0) or 0)}\n",
        "        cache_set(key, out)\n",
        "        return out\n",
        "    return backoff_retry(_call, max_attempts=3, base_delay=0.3)\n",
        "\n",
        "def provider_stooq_history(ticker):\n",
        "    key = f\"stooq:{ticker}\"\n",
        "    cached = cache_get(key)\n",
        "    if cached is not None:\n",
        "        return cached\n",
        "    def _call():\n",
        "        rate_limit(\"stooq\")\n",
        "        try:\n",
        "            import pandas_datareader.data as web\n",
        "            end = datetime.now()\n",
        "            start = end - timedelta(days=7)\n",
        "            df = web.DataReader(ticker.upper(), 'stooq', start=start, end=end)\n",
        "            if df is None or df.empty:\n",
        "                raise RuntimeError(\"stooq empty\")\n",
        "            row = df.iloc[0]\n",
        "            out = {\"provider\": \"stooq\", \"ticker\": ticker, \"price\": float(row[\"Close\"]), \"volume\": int(row.get(\"Volume\", 0) or 0)}\n",
        "            cache_set(key, out)\n",
        "            return out\n",
        "        except Exception:\n",
        "            url = f\"https://stooq.com/q/d/l/?s={ticker.lower()}&i=d\"\n",
        "            r = requests.get(url, timeout=8)\n",
        "            r.raise_for_status()\n",
        "            df = pd.read_csv(pd.compat.StringIO(r.text))\n",
        "            if df.empty:\n",
        "                raise RuntimeError(\"stooq csv empty\")\n",
        "            latest = df.iloc[-1]\n",
        "            out = {\"provider\": \"stooq\", \"ticker\": ticker, \"price\": float(latest[\"Close\"]), \"volume\": int(latest.get(\"Volume\", 0) or 0)}\n",
        "            cache_set(key, out)\n",
        "            return out\n",
        "    return backoff_retry(_call, max_attempts=3, base_delay=0.5)\n",
        "\n",
        "def provider_alpha_vantage_quote(ticker):\n",
        "    if not ALPHAVANTAGE_KEY:\n",
        "        raise RuntimeError(\"Alpha Vantage key not set\")\n",
        "    key = f\"alpha:{ticker}\"\n",
        "    cached = cache_get(key)\n",
        "    if cached is not None:\n",
        "        return cached\n",
        "    def _call():\n",
        "        rate_limit(\"alpha\")\n",
        "        url = \"https://www.alphavantage.co/query\"\n",
        "        params = {\"function\": \"GLOBAL_QUOTE\", \"symbol\": ticker, \"apikey\": ALPHAVANTAGE_KEY}\n",
        "        r = requests.get(url, params=params, timeout=12)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        if \"Global Quote\" not in data or not data[\"Global Quote\"]:\n",
        "            raise RuntimeError(\"alpha empty\")\n",
        "        g = data[\"Global Quote\"]\n",
        "        price = float(g.get(\"05. price\", 0.0))\n",
        "        vol = int(float(g.get(\"06. volume\", 0) or 0))\n",
        "        out = {\"provider\": \"alpha\", \"ticker\": ticker, \"price\": price, \"volume\": vol}\n",
        "        cache_set(key, out)\n",
        "        return out\n",
        "    return backoff_retry(_call, max_attempts=3, base_delay=1.0)\n",
        "\n",
        "def provider_yahoo_json(ticker):\n",
        "    key = f\"yahoo_json:{ticker}\"\n",
        "    cached = cache_get(key)\n",
        "    if cached is not None:\n",
        "        return cached\n",
        "    def _call():\n",
        "        rate_limit(\"yahoo_json\")\n",
        "        url = f\"https://query1.finance.yahoo.com/v7/finance/quote?symbols={ticker}\"\n",
        "        r = requests.get(url, timeout=8)\n",
        "        r.raise_for_status()\n",
        "        j = r.json()\n",
        "        q = j.get(\"quoteResponse\", {}).get(\"result\", [])\n",
        "        if not q:\n",
        "            raise RuntimeError(\"yahoo json empty\")\n",
        "        q0 = q[0]\n",
        "        out = {\"provider\": \"yahoo_json\", \"ticker\": ticker, \"price\": float(q0.get(\"regularMarketPrice\", 0.0)), \"volume\": int(q0.get(\"regularMarketVolume\", 0) or 0)}\n",
        "        cache_set(key, out)\n",
        "        return out\n",
        "    return backoff_retry(_call, max_attempts=2, base_delay=0.5)\n",
        "\n",
        "def provider_polygon_quote(ticker):\n",
        "    key = f\"polygon:{ticker}\"\n",
        "    cached = cache_get(key)\n",
        "    if cached is not None:\n",
        "        return cached\n",
        "    def _call():\n",
        "        rate_limit(\"polygon\")\n",
        "        client = RESTClient()\n",
        "        agg = client.get_previous_close_agg(ticker)\n",
        "        if not agg or not agg.results:\n",
        "            raise RuntimeError(\"polygon empty\")\n",
        "        latest = agg.results[0]\n",
        "        out = {\"provider\": \"polygon\", \"ticker\": ticker, \"price\": latest['c'], \"volume\": latest['v']}\n",
        "        cache_set(key, out)\n",
        "        return out\n",
        "    return backoff_retry(_call, max_attempts=3, base_delay=0.5)\n",
        "\n",
        "# SEC EDGAR helpers (filings/facts)\n",
        "SEC_HEADERS = {\"User-Agent\": SEC_USER_AGENT}\n",
        "\n",
        "def fetch_sec_ticker_cik_map():\n",
        "    key = \"sec_ticker_cik_map\"\n",
        "    cached = cache_get(key)\n",
        "    if cached is not None:\n",
        "        return cached\n",
        "    rate_limit(\"sec\")\n",
        "    url = \"https://www.sec.gov/files/company_tickers.json\"\n",
        "    r = requests.get(url, headers=SEC_HEADERS, timeout=12)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "    mapping = {v[\"ticker\"].upper(): str(v[\"cik_str\"]).zfill(10) for v in data.values()}\n",
        "    cache_set(key, mapping)\n",
        "    return mapping\n",
        "\n",
        "def provider_sec_submissions(ticker):\n",
        "    key = f\"sec_subs:{ticker}\"\n",
        "    cached = cache_get(key)\n",
        "    if cached is not None:\n",
        "        return cached\n",
        "    mapping = fetch_sec_ticker_cik_map()\n",
        "    ticker_up = ticker.upper()\n",
        "    if ticker_up not in mapping:\n",
        "        raise RuntimeError(\"CIK not found for ticker\")\n",
        "    cik = mapping[ticker_up]\n",
        "    rate_limit(\"sec\")\n",
        "    url = f\"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
        "    r = requests.get(url, headers=SEC_HEADERS, timeout=12)\n",
        "    r.raise_for_status()\n",
        "    subs = r.json()\n",
        "    recent = subs.get(\"filings\", {}).get(\"recent\", {})\n",
        "    out = {\"provider\": \"sec\", \"ticker\": ticker, \"recent_forms\": recent.get(\"form\", [])[:10], \"recent_dates\": recent.get(\"filingDate\", [])[:10]}\n",
        "    cache_set(key, out)\n",
        "    return out\n",
        "\n",
        "def provider_sec_company_facts(ticker):\n",
        "    key = f\"sec_facts:{ticker}\"\n",
        "    cached = cache_get(key)\n",
        "    if cached is not None:\n",
        "        return cached\n",
        "    mapping = fetch_sec_ticker_cik_map()\n",
        "    ticker_up = ticker.upper()\n",
        "    if ticker_up not in mapping:\n",
        "        raise RuntimeError(\"CIK not found for ticker\")\n",
        "    cik = mapping[ticker_up]\n",
        "    rate_limit(\"sec\")\n",
        "    url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
        "    r = requests.get(url, headers=SEC_HEADERS, timeout=12)\n",
        "    r.raise_for_status()\n",
        "    facts = r.json()\n",
        "    usgaap = facts.get(\"facts\", {}).get(\"us-gaap\", {})\n",
        "    assets = None\n",
        "    for key_name in (\"Assets\", \"AssetsCurrent\", \"AssetsNoncurrent\"):\n",
        "        if key_name in usgaap:\n",
        "            arr = usgaap[key_name].get(\"units\", {}).get(\"USD\", [])\n",
        "            if arr:\n",
        "                assets = arr[-1].get(\"val\")\n",
        "                break\n",
        "    out = {\"provider\": \"sec\", \"ticker\": ticker, \"assets\": assets}\n",
        "    cache_set(key, out)\n",
        "    return out\n",
        "\n",
        "# Provider priority list and manager\n",
        "PROVIDERS = [\n",
        "    provider_yfinance_quote,\n",
        "    provider_stooq_history,\n",
        "    provider_alpha_vantage_quote if ALPHAVANTAGE_KEY else None,\n",
        "    provider_yahoo_json,\n",
        "    provider_polygon_quote\n",
        "]\n",
        "\n",
        "# filter None\n",
        "PROVIDERS = [p for p in PROVIDERS if p is not None]\n",
        "\n",
        "def fetch_with_fallback(ticker):\n",
        "    last_exc = None\n",
        "    for prov in PROVIDERS:\n",
        "        try:\n",
        "            return prov(ticker)\n",
        "        except Exception as e:\n",
        "            last_exc = e\n",
        "            continue\n",
        "    # price providers failed; return SEC fallback (filings/facts) if available\n",
        "    try:\n",
        "        sec_info = provider_sec_submissions(ticker)\n",
        "        return {\"provider\": \"sec_fallback\", \"ticker\": ticker, \"note\": \"price unavailable\", \"sec\": sec_info}\n",
        "    except Exception:\n",
        "        pass\n",
        "    raise last_exc\n",
        "\n",
        "def bulk_fetch(tickers, max_workers=MAX_WORKERS):\n",
        "    results = {}\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
        "        futures = {ex.submit(fetch_with_fallback, t): t for t in tickers}\n",
        "        for fut in as_completed(futures):\n",
        "            t = futures[fut]\n",
        "            try:\n",
        "                results[t] = fut.result()\n",
        "            except Exception as e:\n",
        "                results[t] = {\"error\": str(e)}\n",
        "    return results\n",
        "\n",
        "# Tickers: create fallback CSV if missing and load\n",
        "def ensure_sp500_csv():\n",
        "    sp500_tickers = pd.DataFrame({\n",
        "        'Symbol': [\n",
        "            'AAPL','MSFT','GOOGL','AMZN','NVDA','META','TSLA','AVGO',\n",
        "            'COST','NFLX','AMD','LIN','ADBE','ACN','TMUS','ABNB','QCOM',\n",
        "            'GLD', 'SLV', 'PBR', 'EC', 'VALE'\n",
        "        ]\n",
        "    })\n",
        "    sp500_tickers.to_csv('sp500_tickers.csv', index=False)\n",
        "\n",
        "ensure_sp500_csv()\n",
        "\n",
        "def load_tickers(txt_path='/content/tickers.txt', csv_path='sp500_tickers.csv'):\n",
        "    if os.path.exists(txt_path):\n",
        "        with open(txt_path, 'r') as f:\n",
        "            tickers = [line.strip() for line in f if line.strip()]\n",
        "    else:\n",
        "        tickers = pd.read_csv(csv_path)['Symbol'].astype(str).str.strip().tolist()\n",
        "    tickers = ['XYZ' if t == 'SQ' else t for t in tickers]\n",
        "    return tickers\n",
        "\n",
        "txt_tickers = load_tickers()\n",
        "print(\"Tickers to fetch (sample):\", txt_tickers[:10])\n",
        "\n",
        "# Fetch initial market data using bulk_fetch\n",
        "print(\"Fetching initial market data (this may take a moment)...\")\n",
        "raw_results = bulk_fetch(txt_tickers)\n",
        "\n",
        "# Build market_data DataFrame from successful price results\n",
        "rows = []\n",
        "for t, res in raw_results.items():\n",
        "    if res is None:\n",
        "        continue\n",
        "    if \"error\" in res:\n",
        "        continue\n",
        "    # price providers return price & volume; sec_fallback returns sec info\n",
        "    if res.get(\"provider\") == \"sec_fallback\":\n",
        "        # skip as price source but keep as metadata if needed\n",
        "        continue\n",
        "    price = res.get(\"price\")\n",
        "    vol = res.get(\"volume\", 0)\n",
        "    if price is None:\n",
        "        continue\n",
        "    rows.append({\n",
        "        'security_id': t,\n",
        "        'underlying_id': t,\n",
        "        'price': float(price),\n",
        "        'volume': int(vol),\n",
        "        'sentiment': 0.0,\n",
        "        'provider': res.get(\"provider\")\n",
        "    })\n",
        "\n",
        "market_data = pd.DataFrame(rows)\n",
        "if market_data.empty:\n",
        "    raise RuntimeError(\"Failed to fetch market data from all providers. Check keys and network.\")\n",
        "\n",
        "print(f\"Fetched price data for {len(market_data)} tickers.\")\n",
        "\n",
        "# Create derivatives\n",
        "derivs = []\n",
        "for _, row in market_data.iterrows():\n",
        "    for d in range(derivative_per_ticker):\n",
        "        deriv = row.copy()\n",
        "        deriv['security_id'] = f\"{row['security_id']}_D{d+1}\"\n",
        "        deriv['price'] = float(row['price']) * float(np.random.uniform(0.95, 1.05))\n",
        "        deriv['volume'] = int(row['volume'] * np.random.uniform(0.1, 0.5))\n",
        "        deriv['sentiment'] = 0.0\n",
        "        derivs.append(deriv)\n",
        "if derivs:\n",
        "    market_data = pd.concat([market_data, pd.DataFrame(derivs)], ignore_index=True)\n",
        "\n",
        "# Convert to tensors safely\n",
        "if market_data.empty:\n",
        "    raise ValueError(\"market_data is empty after fetching. No valid stock data.\")\n",
        "\n",
        "securities = market_data['security_id'].astype(str).tolist()\n",
        "num_agents = len(securities)\n",
        "print(f\"Total agents (including derivatives): {num_agents}\")\n",
        "\n",
        "# Fix: Create agent_prices AND baseline_prices in one shot from the same data\n",
        "price_array = market_data['price'].values\n",
        "agent_prices = torch.tensor(price_array, dtype=torch.float32, device=device)\n",
        "\n",
        "# IMMEDIATE CHECK\n",
        "print(f\"ðŸš¨ agent_prices[19] RIGHT AFTER CREATION = ${agent_prices[19].item():.2f}\")\n",
        "print(f\"ðŸš¨ Expected (from market_data) = ${market_data.iloc[19]['price']:.2f}\")\n",
        "assert abs(agent_prices[19].item() - market_data.iloc[19]['price']) < 0.01, \"Prices don't match!\"\n",
        "\n",
        "baseline_prices = torch.tensor(price_array, dtype=torch.float32, device=device)  # Independent copy, not .clone()\n",
        "\n",
        "# Verify they're identical\n",
        "print(f\"Prices equal after creation: {torch.allclose(agent_prices, baseline_prices)}\")\n",
        "assert torch.allclose(agent_prices, baseline_prices), \"agent_prices and baseline_prices don't match at creation!\"\n",
        "\n",
        "agent_volumes = torch.tensor(market_data['volume'].values, dtype=torch.float32, device=device)\n",
        "agent_sentiment = torch.tensor(market_data['sentiment'].values, dtype=torch.float32, device=device)\n",
        "phi_agents = 1.0 + agent_volumes / (agent_volumes.max() + 1e-9)\n",
        "phi_ladder = torch.tensor(phi_ladder_vals, device=device)\n",
        "\n",
        "# Cluster mapping\n",
        "cluster_map = {}\n",
        "for idx, row in market_data.reset_index().iterrows():\n",
        "    sec = row['security_id']\n",
        "    if '_D' in sec:\n",
        "        parent = sec.rsplit('_D', 1)[0]\n",
        "    else:\n",
        "        parent = row['underlying_id'] if pd.notna(row['underlying_id']) else sec\n",
        "    cluster_map.setdefault(parent, []).append(idx)\n",
        "\n",
        "cluster_indices = {k: torch.tensor(v, dtype=torch.long, device=device) for k, v in cluster_map.items()}\n",
        "\n",
        "# Initialize advanced state tensors\n",
        "# Capital tracking for Basel constraints\n",
        "agent_capital = agent_volumes.clone() * agent_prices.clone()  # initial capital = volume * price\n",
        "\n",
        "# Agent type classification (slow vs fast)\n",
        "num_slow = int(num_agents * SLOW_AGENT_RATIO)\n",
        "is_slow_agent = torch.zeros(num_agents, dtype=torch.bool, device=device)\n",
        "# Assign largest volume agents as \"slow\" (institutional)\n",
        "slow_indices = torch.topk(agent_volumes, num_slow).indices\n",
        "is_slow_agent[slow_indices] = True\n",
        "\n",
        "# Physical inventory for delivery-constrained assets\n",
        "physical_inventory = torch.ones(num_agents, dtype=torch.float32, device=device) * 1000.0  # arbitrary starting inventory\n",
        "is_commodity = torch.zeros(num_agents, dtype=torch.bool, device=device)\n",
        "for idx, sec in enumerate(securities):\n",
        "    underlying = market_data.iloc[idx]['underlying_id'] if '_D' not in sec else sec.rsplit('_D', 1)[0]\n",
        "    if any(ticker in underlying for ticker in COMMODITY_TICKERS):\n",
        "        is_commodity[idx] = True\n",
        "\n",
        "# Memory state\n",
        "agent_memory = agent_prices.clone()\n",
        "\n",
        "# Shock tracking\n",
        "shock_applied = torch.zeros(num_agents, dtype=torch.bool, device=device)\n",
        "\n",
        "print(f\"Agent classification: {is_slow_agent.sum().item()} slow (institutional), {(~is_slow_agent).sum().item()} fast (retail)\")\n",
        "print(f\"Commodity agents: {is_commodity.sum().item()}\")\n",
        "\n",
        "# Market Structure Tweak Functions\n",
        "def apply_basel_constraints(prices, volumes, capital):\n",
        "    \"\"\"1. Basel III capital constraints - force deleveraging if overexposed\"\"\"\n",
        "    if not ENABLE_BASEL_CONSTRAINTS:\n",
        "        return prices\n",
        "\n",
        "    risk_exposure = prices * volumes\n",
        "    max_allowed = MAX_RISK_RATIO * capital\n",
        "    excess = (risk_exposure - max_allowed).clamp(min=0)\n",
        "\n",
        "    overexposed = excess > 0\n",
        "    if overexposed.any():\n",
        "        deleveraging_penalty = DELEVERAGING_SEVERITY * (excess / (capital + 1e-9))\n",
        "        prices = prices * (1 - deleveraging_penalty)\n",
        "\n",
        "    return prices\n",
        "\n",
        "def apply_tiered_liquidity(prices, target_prices, is_slow):\n",
        "    \"\"\"2. Slow agents (institutions) respond with delay\"\"\"\n",
        "    if not ENABLE_TIERED_LIQUIDITY:\n",
        "        return prices\n",
        "\n",
        "    # Fast agents update normally, slow agents move partially toward target\n",
        "    delta = target_prices - prices\n",
        "    slow_delta = SLOW_REACTION_RATE * delta\n",
        "    fast_delta = delta\n",
        "\n",
        "    prices = torch.where(is_slow, prices + slow_delta, prices + fast_delta)\n",
        "    return prices\n",
        "\n",
        "def apply_delivery_friction(prices, volumes, inventory, is_commodity_agent):\n",
        "    \"\"\"3. Physical delivery constraints for commodities\"\"\"\n",
        "    if not ENABLE_DELIVERY_FRICTION:\n",
        "        return prices, inventory\n",
        "\n",
        "    # Attempt to deliver based on volume demand\n",
        "    delivery_attempt = volumes * MAX_DELIVERY_RATE\n",
        "\n",
        "    # Deplete inventory\n",
        "    inventory = inventory - delivery_attempt\n",
        "    inventory = inventory.clamp(min=0)\n",
        "\n",
        "    # Scarcity premium when inventory runs low\n",
        "    scarcity = 1.0 / (inventory + 1.0)  # inverse of available supply\n",
        "    premium = SCARCITY_PREMIUM_FACTOR * scarcity\n",
        "\n",
        "    # Only apply to commodity agents\n",
        "    prices = torch.where(is_commodity_agent, prices * (1 + premium), prices)\n",
        "\n",
        "    return prices, inventory\n",
        "\n",
        "def apply_regime_shock(prices, baseline, cluster_indices, step):\n",
        "    \"\"\"4. Endogenous shocks when clusters diverge too much\"\"\"\n",
        "    if not ENABLE_REGIME_SHOCKS:\n",
        "        return prices\n",
        "\n",
        "    # Check for LATAM energy cluster stress\n",
        "    latam_idxs = []\n",
        "    for idx, sec in enumerate(securities):\n",
        "        underlying = market_data.iloc[idx]['underlying_id'] if '_D' not in sec else sec.rsplit('_D', 1)[0]\n",
        "        if any(ticker in underlying for ticker in LATAM_ENERGY_TICKERS):\n",
        "            latam_idxs.append(idx)\n",
        "\n",
        "    if len(latam_idxs) > 0:\n",
        "        latam_tensor = torch.tensor(latam_idxs, device=device)\n",
        "        divergence = (prices[latam_tensor] - baseline[latam_tensor]).abs().mean()\n",
        "\n",
        "        if divergence > SHOCK_THRESHOLD and not shock_applied[latam_tensor[0]]:\n",
        "            # Apply one-time shock\n",
        "            shock = torch.randn(len(latam_idxs), device=device) * SHOCK_MAGNITUDE\n",
        "            prices[latam_tensor] = prices[latam_tensor] * (1 + shock)\n",
        "            shock_applied[latam_tensor] = True\n",
        "            print(f\"  âš ï¸  REGIME SHOCK applied to LATAM energy cluster at step {step} (divergence: {divergence:.2%})\")\n",
        "\n",
        "    return prices\n",
        "\n",
        "def apply_memory_feedback(prices, memory, alpha, influence):\n",
        "    \"\"\"5. Exponential moving average memory creates support/resistance\"\"\"\n",
        "    if not ENABLE_MEMORY:\n",
        "        return prices, memory\n",
        "\n",
        "    # Update memory: EMA of prices\n",
        "    memory = alpha * prices + (1 - alpha) * memory\n",
        "\n",
        "    # Pull prices slightly toward memory (support/resistance effect)\n",
        "    prices = prices + influence * (memory - prices)\n",
        "\n",
        "    return prices, memory\n",
        "\n",
        "def compute_influence_weighted_consensus(prices, volumes, is_slow):\n",
        "    \"\"\"6. Dollar-weighted agent influence on global consensus\"\"\"\n",
        "    if not ENABLE_INFLUENCE_WEIGHTING:\n",
        "        return prices.mean().item()\n",
        "\n",
        "    # Dollar-weighted power\n",
        "    agent_power = (volumes * prices) / ((volumes * prices).sum() + 1e-9)\n",
        "\n",
        "    # Slow agents get extra weight in consensus\n",
        "    z3_weights = torch.where(is_slow,\n",
        "                             agent_power * SLOW_AGENT_Z3_WEIGHT,\n",
        "                             agent_power)\n",
        "\n",
        "    global_z3 = (prices * z3_weights).sum() / (z3_weights.sum() + 1e-9)\n",
        "    return global_z3.item()\n",
        "\n",
        "# Enhanced Simulation Loop\n",
        "plt.ion()\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "\n",
        "history_global = []\n",
        "top_k = min(20, num_agents)\n",
        "history_top_agents = torch.zeros((max_steps, top_k), device=device)\n",
        "\n",
        "prev_agent_prices = agent_prices.clone()\n",
        "top_indices = torch.topk(agent_volumes, top_k).indices\n",
        "\n",
        "for step in range(max_steps):\n",
        "    ladder_idx = step % len(phi_ladder)\n",
        "    phi_step = 0.2 * phi_agents * phi_ladder[ladder_idx]\n",
        "\n",
        "    # Update sentiment (TODO: Integrate real X sentiment fetch here)\n",
        "    base_sent = 0.0  # Placeholder; replace with actual sentiment calculation\n",
        "    agent_sentiment = torch.full((num_agents,), base_sent, device=device, dtype=torch.float32)\n",
        "    agent_sentiment = torch.clamp(agent_sentiment, -0.5, 0.5)\n",
        "    phi_step = phi_step * (1.0 + 0.3 * agent_sentiment)\n",
        "    phi_step = torch.clamp(phi_step, 0.0, 1.0)\n",
        "\n",
        "    # Cross-agent sampling per cluster\n",
        "    sampled_mean = torch.empty_like(agent_prices)\n",
        "    for parent, idxs in cluster_indices.items():\n",
        "        if idxs.numel() == 0:\n",
        "            continue\n",
        "        k = idxs.numel()\n",
        "        rand_idx = torch.randint(0, k, (k,), device=device)\n",
        "        local_sample = idxs[rand_idx]\n",
        "        local_mean = agent_prices[local_sample].view(k).mean()\n",
        "        sampled_mean[idxs] = local_mean\n",
        "\n",
        "    # Compute global consensus with influence weighting\n",
        "    global_state = compute_influence_weighted_consensus(agent_prices, agent_volumes, is_slow_agent)\n",
        "    sampled_mean = 0.9 * sampled_mean + 0.1 * global_state\n",
        "\n",
        "    # Base price update (target prices)\n",
        "    noise = eta * torch.randn_like(agent_prices)\n",
        "    momentum = 0.01 * (agent_prices - torch.roll(agent_prices, 1))\n",
        "    target_prices = agent_prices + phi_step * (sampled_mean - agent_prices) + noise + momentum\n",
        "\n",
        "    # APPLY TWEAKS IN ORDER\n",
        "    # Tweak 2: Tiered liquidity (slow vs fast agents)\n",
        "    agent_prices = apply_tiered_liquidity(agent_prices, target_prices, is_slow_agent)\n",
        "\n",
        "    # Tweak 5: Memory feedback\n",
        "    agent_prices, agent_memory = apply_memory_feedback(agent_prices, agent_memory, MEMORY_ALPHA, MEMORY_INFLUENCE)\n",
        "\n",
        "    # Tweak 1: Basel III constraints\n",
        "    agent_prices = apply_basel_constraints(agent_prices, agent_volumes, agent_capital)\n",
        "\n",
        "    # Tweak 3: Delivery friction\n",
        "    agent_prices, physical_inventory = apply_delivery_friction(agent_prices, agent_volumes, physical_inventory, is_commodity)\n",
        "\n",
        "    # Tweak 4: Regime shocks\n",
        "    agent_prices = apply_regime_shock(agent_prices, baseline_prices, cluster_indices, step)\n",
        "\n",
        "    # Weak pull toward baseline (original reversion)\n",
        "    revert_strength = 0.01\n",
        "    agent_prices = agent_prices + revert_strength * (baseline_prices - agent_prices)\n",
        "\n",
        "    # Safety checks\n",
        "    if torch.isnan(agent_prices).any() or torch.isinf(agent_prices).any():\n",
        "        print(\"Numerical explosion, stopping at step\", step)\n",
        "        break\n",
        "    if agent_prices.abs().max().item() > 1e6:\n",
        "        print(\"Price magnitude too large, stopping at step\", step)\n",
        "        break\n",
        "\n",
        "    # Store history\n",
        "    history_global.append(global_state)\n",
        "    history_top_agents[step, :top_k] = agent_prices[top_indices].cpu()\n",
        "\n",
        "    # Trend signals\n",
        "    rel_move = (agent_prices - prev_agent_prices) / (prev_agent_prices.abs() + 1e-9)\n",
        "    signals = {}\n",
        "    for i, sec in enumerate(securities):\n",
        "        move = rel_move[i].item()\n",
        "        if move > 0.01:\n",
        "            signals[sec] = 'BUY'\n",
        "        elif move < -0.01:\n",
        "            signals[sec] = 'SELL'\n",
        "        else:\n",
        "            signals[sec] = 'HOLD'\n",
        "\n",
        "    # Plotting every 10 steps\n",
        "    if (step + 1) % 10 == 0 or step == max_steps - 1:\n",
        "        ax1.clear(); ax2.clear()\n",
        "        ax1.plot(history_global, color='blue', linewidth=2, label='Global Z3 (Influence-Weighted)')\n",
        "        ax1.set_title(\"Global Z3 Consensus + Multi-Layer Market Structure\")\n",
        "        ax1.set_ylabel(\"Global Z3 ($)\")\n",
        "        ax1.legend(); ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        for i in range(history_top_agents.shape[1]):\n",
        "            ax2.plot(history_top_agents[:step+1, i].cpu().numpy(), alpha=0.7)\n",
        "        ax2.set_title(\"Top Influencer Agents\")\n",
        "        ax2.set_xlabel(\"Step\"); ax2.set_ylabel(\"Agent Price ($)\")\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        plt.pause(0.01)\n",
        "\n",
        "        active = {k: v for k, v in signals.items() if v != 'HOLD'}\n",
        "        print(f\"\\nStep {step+1}/{max_steps} | Global Z3: ${global_state:.2f}\")\n",
        "\n",
        "        # Show commodity inventory levels if enabled\n",
        "        if ENABLE_DELIVERY_FRICTION and is_commodity.any():\n",
        "            avg_commodity_inventory = physical_inventory[is_commodity].mean().item()\n",
        "            print(f\"  ðŸ“¦ Avg Commodity Inventory: {avg_commodity_inventory:.0f} units\")\n",
        "\n",
        "        for k, v in list(active.items())[:20]:\n",
        "            print(f\"  {k}: {v}\")\n",
        "        print(f\"  ... {len(active)} active signals out of {len(signals)} agents\")\n",
        "\n",
        "    prev_agent_prices = agent_prices.clone()\n",
        "    time.sleep(update_interval)\n",
        "\n",
        "print(\"\\nâœ… Simulation finished.\")\n",
        "\n",
        "# Summary output\n",
        "sample_providers = market_data[['security_id','provider']].drop_duplicates().head(10).to_dict(orient='records')\n",
        "print(f\"Agents: {num_agents}; sample providers for fetched tickers:\")\n",
        "for r in sample_providers:\n",
        "    print(r)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nðŸ” LATAM CLUSTER DIVERGENCE DETAIL\")\n",
        "print(\"=\"*60)\n",
        "latam_tickers = ['PBR', 'EC', 'VALE']\n",
        "for ticker in latam_tickers:\n",
        "    if ticker in securities:  # Check securities list, not market_data\n",
        "        idx = securities.index(ticker)  # Get tensor index from securities list\n",
        "        current = agent_prices[idx].item()\n",
        "        baseline = baseline_prices[idx].item()\n",
        "        divergence = ((current - baseline) / baseline) * 100\n",
        "        print(f\"{ticker:6s} | Current: ${current:7.2f} | Baseline: ${baseline:7.2f} | Divergence: {divergence:+7.2f}%\")"
      ],
      "metadata": {
        "id": "KPpnJ0VboMd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Right after: baseline_prices = agent_prices.clone().detach()\n",
        "# BEFORE any other code\n",
        "\n",
        "print(\"\\nðŸš¨ IMMEDIATE TENSOR CHECK (right after creation)\")\n",
        "print(\"=\"*60)\n",
        "for ticker in ['PBR', 'EC', 'VALE']:\n",
        "    if ticker in securities:\n",
        "        idx = securities.index(ticker)\n",
        "        print(f\"{ticker} | agent_prices[{idx}]=${agent_prices[idx].item():.2f} | baseline_prices[{idx}]=${baseline_prices[idx].item():.2f}\")\n",
        "\n",
        "print(f\"\\nTensor means: agent={agent_prices.mean().item():.2f} | baseline={baseline_prices.mean().item():.2f}\")\n",
        "print(f\"Are they equal? {torch.allclose(agent_prices, baseline_prices)}\")"
      ],
      "metadata": {
        "id": "kcQVg9gWr0uR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}